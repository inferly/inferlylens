{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a27a8ea",
   "metadata": {},
   "source": [
    "# Quick start guide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29dabfa0",
   "metadata": {},
   "source": [
    "This notebook illustrates most of the library functionalities on a regression example. The data we study is a kaggle dataset compiling a series of aerodynamic and acoustic tests of two and three-dimensional airfoils (see the [data card](https://www.kaggle.com/datasets/fedesoriano/airfoil-selfnoise-dataset) for more details).\n",
    "\n",
    "The notebook is structured in two parts, starting with data exploration and finishing with some model visualisation\n",
    "\n",
    "To start with, we import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gpflow\n",
    "\n",
    "import inferlylens as infly\n",
    "import inferlylens.data.plots as dataplot\n",
    "import inferlylens.models.plots as modelplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fef5d0",
   "metadata": {},
   "source": [
    "We now load the data, and define what will be the inputs and outputs for this dataset. Note that the input and output names must correspond to columns of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../datasets/airfoil.parquet\")\n",
    "\n",
    "# we do some basic feature engineering\n",
    "df[\"Log frequency\"] = np.log(df[\"Frequency\"])\n",
    "\n",
    "input_names = ['Log frequency','Angle of attack','Chord length','Free-stream velocity', 'Displacement thickness']\n",
    "output_names = ['Sound pressure']\n",
    "\n",
    "df[\"Frequency\"] = np.log(df[\"Frequency\"])\n",
    "\n",
    "print(\"data shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2909d4a",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "First, let's investigate the input distribution and the relationship with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = dataplot.pairsplot(\n",
    "    df, input_names, opacity=0.2, title=\"Input distribution\", width=1000, height=1000\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = dataplot.gridplot(df, input_names, output_names)\n",
    "fig.update_layout(title='Input vs output', width=1800, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f9543",
   "metadata": {},
   "source": [
    "## Fitting a GP model\n",
    "\n",
    "In this section, we show how to use `inferlylens` to help with data preparation (train/test split and data transform) and use `gpflow` to fit a Gaussian process regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = infly.data.Dataset(df, input_names, output_names)\n",
    "trainset, testset = dataset.split([1300, df.shape[0] - 1300], ['train', 'test'])\n",
    "\n",
    "print(dataset.df.head())\n",
    "print(\"trainset shape:\", trainset.df.shape)\n",
    "print(\"testset shape:\", testset.df.shape)\n",
    "\n",
    "## Separate training input and outputs\n",
    "X = trainset.df[input_names]\n",
    "Y = trainset.df[output_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8b860",
   "metadata": {},
   "source": [
    "When fitting a GP model, it is common practice to rescale the input and output data to improve the robustness of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1cb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the training inputs to the unit cube\n",
    "input_transform = infly.data.transforms.unit_cube_rescaling(X)  # this is a tensorflow Bijector\n",
    "Xt = input_transform.forward(X)\n",
    "\n",
    "# map training output to zero mean and unit variance\n",
    "output_transform = infly.data.transforms.standardise_rescaling(Y)\n",
    "Yt = output_transform.forward(Y)\n",
    "\n",
    "# initialise the GP model. Note that this is a standard GPflow model\n",
    "kernel = gpflow.kernels.Matern52(lengthscales=0.1 * np.ones(len(input_names)), variance=1.0)\n",
    "gpr = gpflow.models.GPR((Xt, Yt), kernel)\n",
    "gpr.likelihood.variance.assign(1e-4)\n",
    "\n",
    "# train the GP model\n",
    "opt = gpflow.optimizers.Scipy()\n",
    "opt_logs = opt.minimize(\n",
    "    gpr.training_loss, gpr.trainable_variables, options={\"maxiter\": 2000}\n",
    ")\n",
    "print(opt_logs)\n",
    "\n",
    "# get model summary\n",
    "gpflow.utilities.print_summary(gpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce802ffc",
   "metadata": {},
   "source": [
    "## Using `inferlylens` to interact with the GP model\n",
    "\n",
    "The main disadvantage of rescaling the input and outputs is that it is then necessary to map the model predictions back into the original space to obtain meaningful values. To make this particularly straightfoward, `inferlylens` offers a thin wrapper around gpflow models that will do this for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpmodel = infly.models.GPmodel(gpr, input_transform, output_transform)\n",
    "\n",
    "# the three methods associated with the GPmodel class are:\n",
    "pred, var = gpmodel.predict_y(Xnew = testset.df[input_names])\n",
    "quantiles = gpmodel.predict_quantiles(Xnew = testset.df[input_names], levels = np.array([0.05, 0.95]))\n",
    "log_lik = gpmodel.predict_log_density(data = testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21ff0c",
   "metadata": {},
   "source": [
    "`inferlylens` also come with some default plots to get some insights into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee61ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = modelplot.plot_lengthscales(gpmodel.gpflow.kernel, input_names, range_r=[0., 1.5])\n",
    "fig.update_layout(title='Lengthscales')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = modelplot.plot_actual_vs_predicted(gpmodel, testset)\n",
    "fig.update_layout(title='Actual vs predicted', width=1000, height=1000)\n",
    "fig.show()\n",
    "\n",
    "ref_pt = np.mean(np.asarray(X), axis=0, keepdims=True)\n",
    "input_range = input_transform.inverse(np.array([[0, 1]] * 5).T)\n",
    "\n",
    "fig = modelplot.plot_slices(gpmodel, input_names, output_names, reference_point=ref_pt, xlim=input_range)\n",
    "fig.update_layout(title='Prediction slices', width=2500, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86748244",
   "metadata": {},
   "source": [
    "Finally, we can compute some modelling performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = infly.models.q2(gpmodel, testset)\n",
    "nlpd = infly.models.nlpd(gpmodel, testset)\n",
    "rmse = infly.models.rmse(gpmodel, testset)\n",
    "\n",
    "print(pd.DataFrame({\"q2\":q2, \"nlpd\":nlpd, \"rmse\":rmse}))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.10.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
